{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27065b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2467b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71575641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "CODE_DIR = \"/content/drive/MyDrive/lib-test\"\n",
    "if CODE_DIR not in sys.path:\n",
    "    sys.path.insert(0, CODE_DIR)\n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a56265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "from metrics import circle_iou, circle_iou_torch\n",
    "from helpers import draw_two_circles_on_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d5f4da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0   0%    0.00kB/s    0:00:00 (xfr#0, to-chk=0/1)\n",
      "Archive:  processed_data.zip\n",
      "replace __MACOSX/._processed_data? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!rsync -a --info=progress2 \"/content/drive/MyDrive/Research-Project-Data/processed_data.zip\" \"/content/\"\n",
    "!unzip processed_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88a7bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25698 25698 True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def load_participants(root: str):\n",
    "\n",
    "    participants = []\n",
    "\n",
    "    for session in os.listdir(root):\n",
    "\n",
    "        session_path = os.path.join(root, session)\n",
    "        for participant in os.listdir(session_path):\n",
    "\n",
    "            if '.zip' in participant:\n",
    "                continue\n",
    "\n",
    "            participant_path = os.path.join(session_path, participant)\n",
    "            participants.append(participant_path)\n",
    "\n",
    "    return participants\n",
    "\n",
    "def get_input_target_lists(participants: List[str]):\n",
    "\n",
    "    expected_cols = [\n",
    "        \"Time in s\",\n",
    "        \"Defined zone\",\n",
    "        \"Point number\",\n",
    "        \"Center-X Zone 1\",\n",
    "        \"Center-Y Zone 1\",\n",
    "        \"Radius Zone 1\",\n",
    "        \"Center-X Zone 2\",\n",
    "        \"Center-Y Zone 2\",\n",
    "        \"Radius Zone 2\"\n",
    "    ]\n",
    "\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for participant_path in participants:\n",
    "\n",
    "        manual_data_df = pd.read_csv(os.path.join(participant_path, \"normalized_results_manual.txt\"), sep='\\t', usecols=expected_cols)\n",
    "        images_path = os.path.join(participant_path, \"video_frames\")\n",
    "\n",
    "        for image in os.listdir(images_path):\n",
    "\n",
    "            image_time_stamp = int(image.split('.')[0][3:])\n",
    "            if image_time_stamp < len(manual_data_df):\n",
    "                info = manual_data_df.iloc[image_time_stamp]\n",
    "                target = (\n",
    "                    float(info['Center-X Zone 1']),\n",
    "                    float(info['Center-Y Zone 1']),\n",
    "                    float(info['Radius Zone 1']),\n",
    "\n",
    "                    float(info['Center-X Zone 2']),\n",
    "                    float(info['Center-Y Zone 2']),\n",
    "                    float(info['Radius Zone 2'])\n",
    "                )\n",
    "\n",
    "                images.append(os.path.join(participant_path, \"video_frames\", image))\n",
    "                targets.append(target)\n",
    "                \n",
    "    return images, targets\n",
    "\n",
    "\n",
    "pars = load_participants('/content/processed_data')\n",
    "images, targets = get_input_target_lists(pars)\n",
    "\n",
    "print(len(images), len(targets), len(images) == len(targets))\n",
    "\n",
    "#####\n",
    "\n",
    "import random\n",
    "\n",
    "pars = sorted(pars)\n",
    "rng = random.Random(42)\n",
    "rng.shuffle(pars)\n",
    "\n",
    "n = len(pars)\n",
    "trainlim = int(0.8 * n)\n",
    "vallim = trainlim + int(0.1 * n)\n",
    "\n",
    "train_pars = pars[:trainlim]\n",
    "val_pars   = pars[trainlim:vallim]\n",
    "test_pars  = pars[vallim:]  # remainder\n",
    "\n",
    "print(len(pars) == (len(train_pars) + len(val_pars) + len(test_pars)))\n",
    "\n",
    "#####\n",
    "\n",
    "train_images, train_targets = get_input_target_lists(train_pars)\n",
    "val_images, val_targets = get_input_target_lists(val_pars)\n",
    "test_images, test_targets = get_input_target_lists(test_pars)\n",
    "print(len(train_images) + len(val_images) + len(test_images) == len(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d03a897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/processed_data/Session2_Light/Participant14']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(train_pars, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5130990a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/content/processed_data/Session1_Light/Participant14',\n",
       "  '/content/processed_data/Session2_Light/Participant19',\n",
       "  '/content/processed_data/Session1_Light/Participant15',\n",
       "  '/content/processed_data/Session1_Light/Participant17'],\n",
       " ['/content/processed_data/Session1_Light/Participant22',\n",
       "  '/content/processed_data/Session1_Light/Participant23',\n",
       "  '/content/processed_data/Session1_Light/Participant3',\n",
       "  '/content/processed_data/Session1_Light/Participant10',\n",
       "  '/content/processed_data/Session1_Light/Participant16',\n",
       "  '/content/processed_data/Session2_Light/Participant3'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pars, test_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04690fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# ImageNet mean and std\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "class ProcessedDataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, transform, out_size=(360, 640)):\n",
    "\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.targets = list(targets)\n",
    "        self.out_h, self.out_w = out_size\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "\n",
    "        y = torch.tensor(self.targets[idx], dtype=torch.float32).clone()    \n",
    "\n",
    "        return img, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c44da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "train_ds = ProcessedDataset(train_images, train_targets, transform=train_tf)\n",
    "val_ds = ProcessedDataset(val_images, val_targets, transform=val_tf)\n",
    "test_ds = ProcessedDataset(test_images, test_targets, transform=val_tf)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_dl  = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Tuple, Callable, Optional\n",
    "\n",
    "class CircleRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = ResNet18_Weights.DEFAULT if pretrained else None\n",
    "        self.backbone = models.resnet18(weights=weights)\n",
    "        \n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        out = self.head(feats)\n",
    "        return out\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def predict_on_cv2_frames(self, frame: np.ndarray, transform: Callable, device: str, verbose: bool=False) -> Tuple[Tuple[float, float, float], Tuple[float, float, float]]:\n",
    "\n",
    "        self.eval()\n",
    "        is_training = self.training\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_pil = Image.fromarray(frame_rgb)\n",
    "        \n",
    "        x = transform(frame_pil)\n",
    "        x = x.unsqueeze(0).to(device)\n",
    "\n",
    "        out = self(x)\n",
    "        out = out.squeeze(0).detach().cpu().tolist()\n",
    "\n",
    "        r_pred = tuple(out[:3])\n",
    "        g_pred = tuple(out[3:])\n",
    "\n",
    "        if is_training: self.train()\n",
    "\n",
    "        return r_pred, g_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052752a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 203MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/5 | Train Loss: 0.070576 | Val Loss: 0.041375 | Time: 440.77s | Finished at: 2026-02-06 16:33:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/5 | Train Loss: 0.031836 | Val Loss: 0.031663 | Time: 437.73s | Finished at: 2026-02-06 16:40:53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/5 | Train Loss: 0.023135 | Val Loss: 0.029443 | Time: 439.78s | Finished at: 2026-02-06 16:48:12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/5 | Train Loss: 0.019030 | Val Loss: 0.023866 | Time: 435.52s | Finished at: 2026-02-06 16:55:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val   05/5:   3%|▎         | 4/126 [00:01<00:40,  3.05it/s, loss=0.03700]  "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device is: {device}\")\n",
    "\n",
    "model = CircleRegressor().to(device)\n",
    "\n",
    "def circle_loss(preds, targets, w_center=1.0, w_radius=2.0, beta=0.02):\n",
    "    \"\"\"\n",
    "    preds/targets: (B, 6) = [cx1, cy1, r1, cx2, cy2, r2], normalized to [0,1]\n",
    "    \"\"\"\n",
    "    preds = preds.view(-1, 2, 3)\n",
    "    targets = targets.view(-1, 2, 3)\n",
    "\n",
    "    pc, pr = preds[..., :2], preds[..., 2]   # centers, radii\n",
    "    tc, tr = targets[..., :2], targets[..., 2]\n",
    "\n",
    "    lc = F.smooth_l1_loss(pc, tc, beta=beta, reduction=\"mean\")\n",
    "    lr = F.smooth_l1_loss(pr, tr, beta=beta, reduction=\"mean\")\n",
    "    return w_center * lc + w_radius * lr\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 5\n",
    "LOSS_FN = circle_loss\n",
    "\n",
    "train_batches_to_use = int(0.45 * len(train_dl))\n",
    "\n",
    "print(\"Training Started ...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0\n",
    "    train_count = 0\n",
    "\n",
    "    train_pbar = tqdm(train_dl, total=len(train_dl), desc=f\"Train {epoch:02d}/{epochs}\", leave=False)\n",
    "    for imgs, targets in train_pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        targets = targets.to(device).float()\n",
    "\n",
    "        preds = model(imgs)\n",
    "        loss = LOSS_FN(preds, targets)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        train_loss_sum += loss.item() * bs\n",
    "        train_count += bs\n",
    "\n",
    "        train_pbar.set_postfix(loss=f\"{loss.item():.5f}\")\n",
    "\n",
    "    avg_train_loss = train_loss_sum / max(1, train_count)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0\n",
    "    val_count = 0\n",
    "\n",
    "    val_pbar = tqdm(test_dl, total=len(test_dl), desc=f\"Val   {epoch:02d}/{epochs}\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_pbar:\n",
    "            imgs = imgs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "\n",
    "            preds = model(imgs)\n",
    "            loss = LOSS_FN(preds, targets)\n",
    "\n",
    "            bs = imgs.size(0)\n",
    "            val_loss_sum += loss.item() * bs\n",
    "            val_count += bs\n",
    "\n",
    "            val_pbar.set_postfix(loss=f\"{loss.item():.5f}\")\n",
    "\n",
    "    avg_val_loss = val_loss_sum / max(1, val_count)\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    finished_at = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{epochs} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} \"\n",
    "        f\"| Time: {epoch_time:.2f}s | Finished at: {finished_at}\"\n",
    "    )\n",
    "\n",
    "i = 1\n",
    "save_path = f\"/content/drive/MyDrive/circle_regressor_v{i}.pt\"\n",
    "while os.path.exists(save_path):\n",
    "    print(\"Path exists\", i)\n",
    "    i += 1\n",
    "    save_path = f\"/content/drive/MyDrive/circle_regressor_v{i}.pt\"\n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "260e08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"/content/drive/MyDrive/circle_regressor_v1.pt\"\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "model = CircleRegressor(True)\n",
    "state = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8508e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\t  processed_data      requirements-colab.txt\n",
      "__MACOSX  processed_data.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "915e49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive\t  processed_data      requirements-colab.txt\n",
      "__MACOSX  processed_data.zip  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc191ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Tuple\n",
    "\n",
    "def evaluate_model_circl_iou(model: CircleRegressor, evaluation_set: 'str'='test', n_batches: int=-1, verbose: bool=False) -> Tuple[float, float]:\n",
    "\n",
    "    eval_set = {\n",
    "        \"train\": train_dl,\n",
    "        \"val\": val_dl,\n",
    "        \"test\": test_dl\n",
    "    }[evaluation_set]\n",
    "\n",
    "    if n_batches > len(eval_set):\n",
    "        print(f\"the chosen set contins less that {n_batches} batches, max n_batch is {len(eval_set)} here\")\n",
    "        print(f\"replacing n_batch with {len(eval_set)} ...\")\n",
    "        n_batches = eval_set\n",
    "\n",
    "    if n_batches == -1:\n",
    "        eval_iter = eval_set\n",
    "        n_batches = len(eval_set)\n",
    "    else:\n",
    "        print(n_batches)\n",
    "        eval_iter = itertools.islice(iter(test_dl), n_batches)\n",
    "\n",
    "    if verbose: print(f\"Evaluating {evaluation_set}, on {n_batches=}\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    running_r_iou = 0.0\n",
    "    running_g_iou = 0.0\n",
    "\n",
    "    for images, targets in eval_iter:\n",
    "\n",
    "        if verbose: print(f\"{images.shape=}, {targets.shape=}\")\n",
    "\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outs = model(images)\n",
    "\n",
    "        r_gt = targets[:, :3]\n",
    "        g_gt = targets[:, 3:]\n",
    "\n",
    "        r_preds = outs[:, :3]\n",
    "        g_preds = outs[:, 3:]\n",
    "\n",
    "        r_iou = circle_iou_torch(r_gt, r_preds)\n",
    "        g_iou = circle_iou_torch(g_gt, g_preds)\n",
    "        \n",
    "        r_iou = r_iou.detach().mean().item()\n",
    "        g_iou = g_iou.detach().mean().item()\n",
    "\n",
    "        if verbose: print(f\"{r_iou=}, {g_iou=}\")\n",
    "\n",
    "        running_r_iou += r_iou\n",
    "        running_g_iou += g_iou\n",
    "\n",
    "    running_r_iou /= n_batches\n",
    "    running_g_iou /= n_batches\n",
    "\n",
    "    return running_r_iou, running_g_iou\n",
    "\n",
    "def predict_on_cv2_frames(model: CircleRegressor, frame, transform, device='cpu', verbose: bool=False) -> Tuple[Tuple[float, float, float], Tuple[float, float, float]]:\n",
    "\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_pil = Image.fromarray(frame)\n",
    "    \n",
    "    x = transform(frame_pil)\n",
    "    x = x.unsqueeze(0).to(device)\n",
    "\n",
    "    out = model(x)\n",
    "    out = out.squeeze(0).detach().cpu().tolist()\n",
    "\n",
    "    r_pred = tuple(out[:3])\n",
    "    g_pred = tuple(out[3:])\n",
    "\n",
    "    return r_pred, g_pred\n",
    "\n",
    "img = cv2.imread(\"/content/processed_data/Session1_Light/Participant17/video_frames/img160.jpg\")\n",
    "\n",
    "r, g = predict_on_cv2_frames(model, img, transform=val_tf)\n",
    "\n",
    "\n",
    "# running_r_iou, running_g_iou = evaluate_model_circl_iou(model, evaluation_set='test', n_batches=2, verbose=True)\n",
    "# print(f\"Average IOU: {running_r_iou=}, {running_g_iou=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
